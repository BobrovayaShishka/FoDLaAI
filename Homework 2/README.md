# Отчет по заданию 1: Модификация моделей

## Цель
Расширить базовые реализации линейной и логистической регрессии с использованием PyTorch, добавив функциональность для улучшения обучения и оценки качества модели.

---

## Задание 1.1: Линейная регрессия с регуляризацией и ранней остановкой

### Реализация:
- Создан класс `LinearRegressionWithRegularization`, наследующий `nn.Module`.
- Добавлена поддержка **L1** и **L2 регуляризации** через метод `regularization_loss()`.
- Функция `train_linear_regression()` реализует обучение с:
  - Поддержкой **DataLoader**
  - Ранней остановкой (патиенс = 5)
  - Визуализацией графиков потерь
  - Сохранением графиков в файлы

---

## Задание 1.2: Логистическая регрессия с многоклассовой классификацией и метриками

### Реализация:
- Создан класс `MulticlassLogisticRegression` для **многоклассовой классификации**
- Функция `train_logistic_regression()` расширена:
  - Поддержка **CrossEntropyLoss**
  - Вычисление метрик: **precision**, **recall**, **F1-score**, **ROC-AUC**
  - Визуализация матрицы ошибок (`confusion matrix`)
  - Графики метрик по эпохам
  - Логирование метрик в консоль

---

# Отчет по заданию 2: Работа с датасетами

## Цель
Реализовать кастомный `Dataset` класс для работы с CSV-файлами и протестировать его на реальных датасетах для регрессии и бинарной классификации.

---

## Задание 2.1: Кастомный Dataset класс

### Реализация:
Создан класс `CustomCSVDataset`, наследующий `torch.utils.data.Dataset`. Он поддерживает:

- **Загрузку данных из CSV файла**
- **Обработку пропущенных значений**:
  - Числовые: заполнение средним
  - Категориальные: заполнение модой
- **Кодирование категориальных признаков** с помощью `LabelEncoder`
- **Нормализацию числовых признаков** (`StandardScaler`)
- **Автоматическое определение типа задачи** (классификация или регрессия)
- **Преобразование в тензоры PyTorch**


## Задание 2.2: Эксперименты с датасетами

### Использованные датасеты:
- **housing.csv** — задача регрессии
- **heart_disease_uci.csv** — задача бинарной классификации


### Подход:
- Данные загружались через `CustomCSVDataset`
- Разделялись на обучающую и валидационную выборки (80/20)
- Обучались модели:
  - Логистическая регрессия (для классификации)
  - Линейная регрессия (для предсказания цен)

### Модели:
- `MulticlassLogisticRegression` использовалась для бинарной классификации (2 класса)
- `LinearRegressionWithRegularization` использовалась для регрессии

---

# Отчет по домашнему заданию 3: Эксперименты с гиперпараметрами и feature engineering

## Цель задания

Исследовать влияние различных гиперпараметров (learning rate, batch size, оптимизатор) на качество обучения модели, а также изучить эффект от применения методов feature engineering.

---

## Выполненные задачи

### 3.1 Исследование гиперпараметров

**Цель:** исследовать влияние следующих параметров на обучение линейной и логистической регрессии:
- Скорость обучения (`learning_rate`)
- Размер батча (`batch_size`)
- Оптимизатор (`SGD`, `Adam`, `RMSprop`)

### 3.2 Feature Engineering

**Цель:** улучшить качество модели за счет добавления новых признаков:
- Полиномиальные признаки
- Статистические признаки (среднее, дисперсия)
- Сравнение качества моделей с разными типами признаков

---

## Результаты экспериментов

### 3.1 Результаты исследования гиперпараметров

#### Линейная регрессия:

| learning_rate | batch_size | optimizer | best_val_loss | epochs_run |
|--------------|------------|-----------|----------------|-------------|
| 0.001        | 16         | SGD       | 2.336          | 100         |
| 0.001        | 16         | Adam      | 18621.176      | 100         |
| 0.010        | 16         | SGD       | 2.261          | 20          |
| 0.100        | 16         | SGD       | 1.729          | 10          |

**Выводы:**
- **SGD** показывает лучшие результаты при высокой скорости обучения (`lr=0.1`)
- **Adam** и **RMSprop** имеют тенденцию к переобучению или плохой сходимости при неподходящих значениях `lr`
- Модель останавливается раньше при более высоких значениях `lr`

#### Логистическая регрессия:

| learning_rate | batch_size | optimizer | best_val_loss |
|--------------|------------|-----------|----------------|
| 0.001        | 16         | SGD       | 0.9566         |
| 0.001        | 16         | Adam      | 0.9542         |
| 0.010        | 16         | SGD       | 0.9522         |
| 0.100        | 32         | SGD       | 0.9477         |

**Выводы:**
- **SGD** работает стабильнее при увеличении `lr`
- **Adam** может давать хорошие результаты, но требует тонкой настройки `lr`
- Лучшая модель достигла `val_loss = 0.9477`

---

### 3.2 Результаты feature engineering

#### Для линейной регрессии:

| feature_type | best_val_loss | final_train_loss |
|--------------|---------------|------------------|
| Base         | 0.8599        | 97.04            |
| Polynomial   | 0.9492        | 97.04            |
| With Stats   | 0.6999        | 87.63            |

**Выводы:**
- Добавление статистических признаков дало **наилучший результат**
- Полиномиальные признаки **не улучшили** качество, возможно, они привели к переобучению

#### Для логистической регрессии:

| feature_type | best_val_loss |
|--------------|---------------|
| Base         | 0.4757        |
| Polynomial   | 0.2913        |
| With Stats   | 0.4762        |

**Выводы:**
- **Полиномиальные признаки** показали **наилучшее качество**
- Статистические признаки не улучшили модель в данном случае

---

## Анализ гиперпараметров

### Лучшие параметры:
- **Линейная регрессия**: `lr=0.1`, `batch_size=16`, `optimizer=SGD`
- **Логистическая регрессия**: `lr=0.1`, `batch_size=32`, `optimizer=SGD`

### Заключение:
- **SGD** показал себя лучше других оптимизаторов в большинстве случаев
- **Adam** чувствителен к значению `lr` и может давать худшие результаты при больших значениях
- **Ранняя остановка** позволила избежать переобучения

---

## Анализ Feature Engineering

### Применённые методы:
- Полиномиальные признаки (degree=2)
- Статистические признаки: среднее и дисперсия по строкам

### Эффективность:
- **Для регрессии**:
  - Статистические признаки — **наиболее эффективны**
  - Полиномиальные — **ухудшают** качество
- **Для классификации**:
  - Полиномиальные признаки — **наиболее эффективны**
  - Статистические признаки — **не помогают**
